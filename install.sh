#!/bin/bash

# DQai - CLI LLM Shell Kurulum Scripti
# Bu script DQai uygulamasÄ±nÄ± ve gerekli baÄŸÄ±mlÄ±lÄ±klarÄ± kurar

set -e

echo "ğŸš€ DQai CLI LLM Shell Kurulumu BaÅŸlÄ±yor..."
echo "=========================================="

# Renk kodlarÄ±
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Python versiyonunu kontrol et
echo -e "${BLUE}ğŸ“‹ Python versiyonu kontrol ediliyor...${NC}"
if command -v python3 &> /dev/null; then
    PYTHON_VERSION=$(python3 --version | cut -d' ' -f2)
    echo -e "${GREEN}âœ… Python $PYTHON_VERSION bulundu${NC}"
else
    echo -e "${RED}âŒ Python3 bulunamadÄ±! LÃ¼tfen Python 3.10+ yÃ¼kleyin.${NC}"
    exit 1
fi

# Python versiyonunu kontrol et (3.10+)
PYTHON_MAJOR=$(echo $PYTHON_VERSION | cut -d'.' -f1)
PYTHON_MINOR=$(echo $PYTHON_VERSION | cut -d'.' -f2)

if [ "$PYTHON_MAJOR" -lt 3 ] || ([ "$PYTHON_MAJOR" -eq 3 ] && [ "$PYTHON_MINOR" -lt 10 ]); then
    echo -e "${RED}âŒ Python 3.10+ gerekli! Mevcut versiyon: $PYTHON_VERSION${NC}"
    exit 1
fi

# Ollama kontrolÃ¼
echo -e "${BLUE}ğŸ“‹ Ollama kontrol ediliyor...${NC}"
if command -v ollama &> /dev/null; then
    echo -e "${GREEN}âœ… Ollama bulundu${NC}"
else
    echo -e "${YELLOW}âš ï¸  Ollama bulunamadÄ±. Kuruluyor...${NC}"
    
    # Ä°ÅŸletim sistemine gÃ¶re Ollama kurulumu
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        echo -e "${BLUE}ğŸ macOS iÃ§in Ollama kuruluyor...${NC}"
        if command -v brew &> /dev/null; then
            brew install ollama
        else
            echo -e "${RED}âŒ Homebrew bulunamadÄ±! LÃ¼tfen Ã¶nce Homebrew yÃ¼kleyin.${NC}"
            echo "https://brew.sh adresinden Homebrew kurulumu yapabilirsiniz."
            exit 1
        fi
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        echo -e "${BLUE}ğŸ§ Linux iÃ§in Ollama kuruluyor...${NC}"
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo -e "${RED}âŒ Desteklenmeyen iÅŸletim sistemi: $OSTYPE${NC}"
        echo "LÃ¼tfen manuel olarak Ollama kurun: https://ollama.ai"
        exit 1
    fi
fi

# Python baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± kur
echo -e "${BLUE}ğŸ“¦ Python baÄŸÄ±mlÄ±lÄ±klarÄ± kuruluyor...${NC}"
if [ -f "requirements.txt" ]; then
    pip3 install -r requirements.txt
    echo -e "${GREEN}âœ… Python baÄŸÄ±mlÄ±lÄ±klarÄ± kuruldu${NC}"
else
    echo -e "${RED}âŒ requirements.txt dosyasÄ± bulunamadÄ±!${NC}"
    exit 1
fi

# Script'i Ã§alÄ±ÅŸtÄ±rÄ±labilir yap
echo -e "${BLUE}ğŸ”§ Script Ã§alÄ±ÅŸtÄ±rÄ±labilir yapÄ±lÄ±yor...${NC}"
chmod +x llm_shell.py
echo -e "${GREEN}âœ… Script Ã§alÄ±ÅŸtÄ±rÄ±labilir yapÄ±ldÄ±${NC}"

# Ollama servisini baÅŸlat
echo -e "${BLUE}ğŸš€ Ollama servisi baÅŸlatÄ±lÄ±yor...${NC}"
if ! pgrep -x "ollama" > /dev/null; then
    echo -e "${YELLOW}âš ï¸  Ollama servisi baÅŸlatÄ±lÄ±yor...${NC}"
    ollama serve &
    sleep 3
fi

# Test modellerini kontrol et
echo -e "${BLUE}ğŸ“‹ Mevcut modeller kontrol ediliyor...${NC}"
python3 llm_shell.py list-models

echo ""
echo -e "${GREEN}ğŸ‰ Kurulum tamamlandÄ±!${NC}"
echo "=========================================="
echo ""
echo -e "${BLUE}ğŸš€ Kullanmaya baÅŸlamak iÃ§in:${NC}"
echo -e "${GREEN}python3 llm_shell.py shell --model qwen${NC}"
echo ""
echo -e "${BLUE}ğŸ“š YardÄ±m iÃ§in:${NC}"
echo -e "${GREEN}python3 llm_shell.py --help${NC}"
echo ""
echo -e "${BLUE}ğŸ“– DetaylÄ± dokÃ¼mantasyon iÃ§in README.md dosyasÄ±nÄ± okuyun.${NC}"
echo ""
echo -e "${YELLOW}ğŸ’¡ Ä°pucu: Modelleri yÃ¼klemek iÃ§in:${NC}"
echo -e "${GREEN}python3 llm_shell.py install-model qwen${NC}"
echo "" 