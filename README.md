# DQai - CLI LLM Shell ğŸš€

Claude Code tarzÄ±nda, terminal Ã¼zerinden kullanÄ±labilen hafif ve Ã¶zelleÅŸtirilebilir LLM sohbet uygulamasÄ±.

## âœ¨ Ã–zellikler

- ğŸ¯ **Hafif ve HÄ±zlÄ±**: Minimal baÄŸÄ±mlÄ±lÄ±k, hÄ±zlÄ± baÅŸlatma
- ğŸ¤– **Ã‡oklu Model DesteÄŸi**: Qwen, DeepSeek, CodeLlama, Llama2, Mistral
- ğŸ’¾ **GeÃ§miÅŸ Kaydetme**: Ä°steÄŸe baÄŸlÄ± sohbet geÃ§miÅŸi kaydetme
- ğŸ”§ **Ã–zelleÅŸtirilebilir**: Sistem prompt, Ã§ok satÄ±rlÄ± giriÅŸ desteÄŸi
- ğŸ¨ **GÃ¼zel ArayÃ¼z**: Rich kÃ¼tÃ¼phanesi ile renkli terminal arayÃ¼zÃ¼
- ğŸ“¦ **Kolay Kurulum**: Tek komutla model yÃ¼kleme

## ğŸ› ï¸ Kurulum

### 1. Ollama Kurulumu

```bash
# macOS
brew install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh

# Windows
# https://ollama.ai/download adresinden indirin
```

### 2. Python BaÄŸÄ±mlÄ±lÄ±klarÄ±

```bash
pip install -r requirements.txt
```

### 3. Modelleri YÃ¼kleme

```bash
# Temel modeller
ollama pull qwen:7b
ollama pull deepseek-coder:6.7b

# Ek modeller (isteÄŸe baÄŸlÄ±)
ollama pull codellama:7b
ollama pull llama2:7b
ollama pull mistral:7b
```

## ğŸš€ KullanÄ±m

### Temel KullanÄ±m

```bash
# Qwen modeli ile baÅŸlat
python llm_shell.py shell --model qwen

# DeepSeek modeli ile baÅŸlat
python llm_shell.py shell --model deepseek

# GeÃ§miÅŸi kaydet
python llm_shell.py shell --model qwen --save-history
```

### GeliÅŸmiÅŸ SeÃ§enekler

```bash
# Ã‡ok satÄ±rlÄ± giriÅŸ desteÄŸi
python llm_shell.py shell --model qwen --multi-line

# Ã–zel sistem prompt
python llm_shell.py shell --model deepseek --system-prompt "Sen bir Python uzmanÄ±sÄ±n"

# Ã–zel geÃ§miÅŸ dosyasÄ±
python llm_shell.py shell --model qwen --save-history --history-file my_chat.txt
```

### YardÄ±mcÄ± Komutlar

```bash
# Mevcut modelleri listele
python llm_shell.py list-models

# Model yÃ¼kle
python llm_shell.py install-model qwen
```

## ğŸ“‹ Komut ReferansÄ±

### `shell` Komutu

```bash
python llm_shell.py shell [OPTIONS]
```

**SeÃ§enekler:**
- `--model TEXT`: Model seÃ§ (qwen, deepseek, codellama, llama2, mistral)
- `--save-history`: GeÃ§miÅŸi kaydet
- `--history-file TEXT`: GeÃ§miÅŸ dosyasÄ± adÄ± (varsayÄ±lan: chat_history.txt)
- `--system-prompt TEXT`: Sistem prompt'u
- `--multi-line`: Ã‡ok satÄ±rlÄ± giriÅŸ desteÄŸi

### `list-models` Komutu

```bash
python llm_shell.py list-models
```

Desteklenen ve yÃ¼klÃ¼ modelleri listeler.

### `install-model` Komutu

```bash
python llm_shell.py install-model <MODEL_NAME>
```

Belirtilen modeli Ollama Ã¼zerinden yÃ¼kler.

## ğŸ¯ Desteklenen Modeller

| Model | Ollama AdÄ± | AÃ§Ä±klama |
|-------|------------|----------|
| qwen | qwen:7b | Alibaba'nÄ±n Qwen modeli |
| deepseek | deepseek-coder:6.7b | DeepSeek'in kod odaklÄ± modeli |
| codellama | codellama:7b | Meta'nÄ±n kod odaklÄ± modeli |
| llama2 | llama2:7b | Meta'nÄ±n Llama2 modeli |
| mistral | mistral:7b | Mistral AI'nin modeli |

## ğŸ’¡ KullanÄ±m Ã–rnekleri

### Kod Yazma
```
ğŸ§  Sen: Python'da bir web scraper yaz
ğŸ¤– YanÄ±t: [Kod Ã¶rneÄŸi...]
```

### Ã‡ok SatÄ±rlÄ± Kod
```
ğŸ§  Sen (Ã§ok satÄ±rlÄ±, 'END' ile bitir):
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n-1) + fibonacci(n-2)
END
```

### Sistem Prompt ile
```bash
python llm_shell.py shell --model deepseek --system-prompt "Sen bir gÃ¼venlik uzmanÄ±sÄ±n"
```

## ğŸ”§ Ã–zelleÅŸtirme

### Yeni Model Ekleme

`llm_shell.py` dosyasÄ±ndaki `MODELS` sÃ¶zlÃ¼ÄŸÃ¼ne yeni model ekleyebilirsiniz:

```python
MODELS = {
    "qwen": "qwen:7b",
    "deepseek": "deepseek-coder:6.7b",
    "yeni-model": "yeni-model:versiyon"  # Yeni model
}
```

### Ã–zel Sistem Prompt'larÄ±

```bash
# Python uzmanÄ±
--system-prompt "Sen deneyimli bir Python geliÅŸtiricisisin"

# GÃ¼venlik uzmanÄ±
--system-prompt "Sen bir siber gÃ¼venlik uzmanÄ±sÄ±n"

# Ã‡evirmen
--system-prompt "Sen profesyonel bir Ã§evirmensin"
```

## ğŸ“ Dosya YapÄ±sÄ±

```
DQai/
â”œâ”€â”€ llm_shell.py          # Ana uygulama
â”œâ”€â”€ requirements.txt      # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”œâ”€â”€ README.md            # Bu dosya
â””â”€â”€ chat_history.txt     # GeÃ§miÅŸ dosyasÄ± (otomatik oluÅŸur)
```

## ğŸ› Sorun Giderme

### Ollama BaÄŸlantÄ± HatasÄ±
```bash
# Ollama servisini baÅŸlat
ollama serve

# Servisin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kontrol et
curl http://localhost:11434/api/tags
```

### Model BulunamadÄ±
```bash
# Modeli yÃ¼kle
ollama pull qwen:7b

# YÃ¼klÃ¼ modelleri listele
ollama list
```

### Python BaÄŸÄ±mlÄ±lÄ±k HatasÄ±
```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yeniden yÃ¼kle
pip install -r requirements.txt --upgrade
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit yapÄ±n (`git commit -m 'Add amazing feature'`)
4. Push yapÄ±n (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ™ TeÅŸekkÃ¼rler

- [Ollama](https://ollama.ai) - Yerel LLM Ã§alÄ±ÅŸtÄ±rma
- [Typer](https://typer.tiangolo.com) - CLI framework
- [Rich](https://rich.readthedocs.io) - Terminal formatlamasÄ±
- [Requests](https://requests.readthedocs.io) - HTTP istekleri

---

**DQai** - Terminal Ã¼zerinden AI deneyimi! ğŸš€ 